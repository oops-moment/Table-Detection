{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpVboCXNcFax"
      },
      "source": [
        "Object detection (via Detectron2).\n",
        "\n",
        "Optical character recognition (OCR) (via Tesseract and PyTesseract)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fYeYVp2klFt"
      },
      "source": [
        "# Multi-Type-TD-TSR Demo Notebook\n",
        "## 1. Install all the prerequisite\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s9dI-UTk2JEG",
        "outputId": "2edffc5c-908f-4f2c-ad1f-89363a2ecfc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n",
            "2.5.1+cu121 True\n",
            "gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,460 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# install dependencies:\n",
        "!pip install pyyaml\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n",
        "import torch, torchvision\n",
        "torch.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mgOh_aLeciUA"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start_time=time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KO-4u9fQcgR6",
        "outputId": "cfd0a9eb-43a5-4bf2-d9e1-b0bd88f69170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-epbf__uj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-epbf__uj\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit c69939aa85460e8135f40bce908a6cddaa73065f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (11.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.8.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.5.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.1.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.17.1)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6355066 sha256=89ace5d2210265a02444096a30b097d769ecefd4973a8e41def4e9c43bb9b036\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9t534j49/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=5d1adbefbfd27560db888fe48440f7fbba442bbf694e462184400949d31c26f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=b75a0142009c1cd138892e36897864833b11b189de336418e94363cd83f93d78\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-24.10.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.0.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "78f721f81acc4382b5df056361b86cdb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCnCQxc2dGdy",
        "outputId": "1663108e-215b-49a3-e1ab-70d6a455cfe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for loading the modules 281.64215421676636\n"
          ]
        }
      ],
      "source": [
        "end_time=time.time()\n",
        "print(\"Time taken for loading the modules\",end_time-start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gNRcrTxadSP_"
      },
      "outputs": [],
      "source": [
        "start_time_repo=time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQUnnsinlQVT"
      },
      "source": [
        "## 2. Clone the Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XTodlMS3k6gL"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/Psarpei/Multi-Type-TD-TSR.git\n",
        "# !mv Multi-Type-TD-TSR/ Multi_Type_TD_TSR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzywSWN0mPqt"
      },
      "source": [
        "## 3. Download Table Detection Weights and Configuration File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PM35KxbmQBp",
        "outputId": "4ecdb11c-1f1c-4a7b-e4c3-44e412a6614a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=11FgFTy0MyVUMGd00T_InEDaarB4qAlP8\n",
            "From (redirected): https://drive.google.com/uc?id=11FgFTy0MyVUMGd00T_InEDaarB4qAlP8&confirm=t&uuid=f3f0eee7-853d-4fe6-b291-1e5fb615f4ac\n",
            "To: /content/model_final.pth\n",
            "100% 1.10G/1.10G [00:31<00:00, 34.6MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WBk6kHHyvyEzoPBsRr2BvFY51zURjd4R\n",
            "To: /content/All_X152.yaml\n",
            "100% 534/534 [00:00<00:00, 2.32MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PfA2uws919gc893-x9uMIz06zWEko8nF\n",
            "To: /content/Base-RCNN-FPN.yaml\n",
            "100% 1.36k/1.36k [00:00<00:00, 7.10MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 11FgFTy0MyVUMGd00T_InEDaarB4qAlP8\n",
        "!gdown --id 1WBk6kHHyvyEzoPBsRr2BvFY51zURjd4R\n",
        "!gdown --id 1PfA2uws919gc893-x9uMIz06zWEko8nF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIF1OtU6dXNU",
        "outputId": "c77bc0ef-6f4e-4012-8f79-385f097a3af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to clone the repo and download the weights 46.289571046829224\n"
          ]
        }
      ],
      "source": [
        "clone_time_repo=time.time()\n",
        "print(\"Time taken to clone the repo and download the weights\",clone_time_repo-start_time_repo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAcoWOJhuy9f"
      },
      "source": [
        "## 4. Import Everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APmN3Hzy2hBT",
        "outputId": "1acdfb95-96d4-480d-951e-c1472cf6bf29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Logger detectron2 (DEBUG)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import detectron2\n",
        "import deskew as deskew\n",
        "import table_detection as table_detection\n",
        "import table_structure_recognition_all as tsra\n",
        "import table_xml as txml\n",
        "import table_ocr as tocr\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import itertools\n",
        "import random\n",
        "from detectron2.utils.logger import setup_logger\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from google.colab.patches import cv2_imshow\n",
        "setup_logger()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: made some changes to this file so. ned to cat to see the content /content/Multi_Type_TD_TSR/google_colab/table_structure_recognition_all.py\n",
        "\n",
        "!cat table_structure_recognition_all.py"
      ],
      "metadata": {
        "id": "z-n0pSSt8BQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c54294c-d873-4103-950a-402cc68487d7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import cv2\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "import csv\n",
            "\n",
            "\n",
            "from google.colab.patches import cv2_imshow\n",
            "\n",
            "try:\n",
            "    from PIL import Image\n",
            "except ImportError:\n",
            "    import Image\n",
            "import pytesseract as tess\n",
            "import pytesseract\n",
            "\n",
            "\n",
            "def recognize_structure(img):\n",
            "    #tess.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
            "\n",
            "    #print(img.shape)\n",
            "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
            "    img_height, img_width = img.shape\n",
            "\n",
            "    #print(\"img_height\", img_height, \"img_width\", img_width)\n",
            "    #cv2_imshow(img,)\n",
            "\n",
            "    # thresholding the image to a binary image\n",
            "    thresh, img_bin = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY)\n",
            "    #thresh, img_bin = cv2.threshold(img, 160, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
            "    #img_bin = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,5,5)\n",
            "\n",
            "    #cv2_imshow(img_bin)\n",
            "\n",
            "    contours, hierarchy = cv2.findContours(img_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
            "\n",
            "    #invert = False\n",
            "    invert = False\n",
            "    for c in contours:\n",
            "        x, y, w, h = cv2.boundingRect(c)\n",
            "        #print(\"x\", x, \"y\", y, \"w\", w, \"h\", h)\n",
            "        if (w < 0.9 * img_width and h < 0.9*img_height and (w > max(10,img_width / 30) and h > max(10,img_height / 30))):\n",
            "        #if(w*h > 100 and (w < 0.9 * img_width and h < 0.9*img_height)):\n",
            "            #invert = True\n",
            "            invert = True\n",
            "            #print(\"size\", img_width * img_height)\n",
            "            #image = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
            "            img_bin[y:y+h,x:x+w] = 255 - img_bin[y:y+h,x:x+w]\n",
            "\n",
            "    #cv2_imshow(img_bin)\n",
            "\n",
            "    img_bin = 255 - img_bin if (invert) else img_bin\n",
            "\n",
            "    #cv2_imshow(img_bin)\n",
            "\n",
            "    img_bin_inv = 255 - img_bin\n",
            "\n",
            "    #cv2_imshow(img_bin_inv)\n",
            "\n",
            "    ############################################################################################################################################\n",
            "    \n",
            "    kernel_len_ver = max(10, img_height // 50)\n",
            "    kernel_len_hor = max(10, img_width // 50)\n",
            "    # Defining a vertical kernel to detect all vertical lines of image\n",
            "    ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_len_ver)) #shape (kernel_len, 1) inverted! xD\n",
            "    #print(\"ver\", ver_kernel)\n",
            "    #print(ver_kernel.shape)\n",
            "\n",
            "    # Defining a horizontal kernel to detect all horizontal lines of image\n",
            "    hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_len_hor, 1)) #shape (1,kernel_ken) xD\n",
            "    #print(\"hor\", hor_kernel)\n",
            "    #print(hor_kernel.shape)\n",
            "\n",
            "\n",
            "    # A kernel of 2x2\n",
            "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
            "    #print(kernel)\n",
            "    #print(kernel.shape)\n",
            "\n",
            "    # Use vertical kernel to detect and save the vertical lines in a jpg\n",
            "    image_1 = cv2.erode(img_bin_inv, ver_kernel, iterations=3)\n",
            "    vertical_lines = cv2.dilate(image_1, ver_kernel, iterations=4)\n",
            "    \n",
            "    # Plot the generated image\n",
            "    #cv2_imshow(image_1)\n",
            "    \n",
            "    #cv2_imshow(vertical_lines)\n",
            "\n",
            "    # Use horizontal kernel to detect and save the horizontal lines in a jpg\n",
            "    image_2 = cv2.erode(img_bin_inv, hor_kernel, iterations=3)\n",
            "    horizontal_lines = cv2.dilate(image_2, hor_kernel, iterations=5)\n",
            "    # Plot the generated image\n",
            "    #cv2_imshow(image_2)\n",
            "    \n",
            "    #cv2_imshow(horizontal_lines)\n",
            "\n",
            "    \n",
            "    # Combine horizontal and vertical lines in a new third image, with both having same weight.\n",
            "    img_vh = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0.0)\n",
            "    #cv2_imshow(img_vh)\n",
            "\n",
            "    # Eroding and thesholding the image\n",
            "    img_vh = cv2.dilate(img_vh, kernel, iterations=3)\n",
            "    #cv2_imshow(img_vh)\n",
            "\n",
            "\n",
            "    \n",
            "    thresh, img_vh = (cv2.threshold(img_vh, 50, 255, cv2.THRESH_BINARY ))\n",
            "\n",
            "    #print(\"last\")\n",
            "    #cv2_imshow(img_vh)\n",
            "\n",
            "    #print(\"img_bin\")\n",
            "    #cv2_imshow(img_bin)\n",
            "    \n",
            "    #print(\"bitor\")\n",
            "    bitor = cv2.bitwise_or(img_bin, img_vh)\n",
            "    #cv2_imshow(bitor)\n",
            "\n",
            "    \n",
            "    img_median = bitor #cv2.medianBlur(bitor, 3)\n",
            "    #cv2_imshow(img_median)\n",
            "\n",
            "    \n",
            "    ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, img_height*2)) #shape (kernel_len, 1) inverted! xD\n",
            "    vertical_lines = cv2.erode(img_median, ver_kernel, iterations=1)\n",
            "    #cv2_imshow(vertical_lines)\n",
            "\n",
            "    hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (img_width*2, 3)) #shape (kernel_len, 1) inverted! xD\n",
            "    horizontal_lines = cv2.erode(img_median, hor_kernel, iterations=1)\n",
            "    #cv2_imshow(horizontal_lines)\n",
            "\n",
            "    \n",
            "    # A kernel of 2x2\n",
            "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
            "    #print(kernel)\n",
            "    #print(kernel.shape)\n",
            "\n",
            "    # Combine horizontal and vertical lines in a new third image, with both having same weight.\n",
            "    img_vh = cv2.addWeighted(vertical_lines, 0.5, horizontal_lines, 0.5, 0.0)\n",
            "    #cv2_imshow(img_vh)\n",
            "\n",
            "    #cv2_imshow(~img_vh)\n",
            "\n",
            "    # Eroding and thesholding the image\n",
            "    img_vh = cv2.erode(~img_vh, kernel, iterations=2)\n",
            "    #cv2_imshow(img_vh)\n",
            "\n",
            "    thresh, img_vh = cv2.threshold(img_vh, 128, 255, cv2.THRESH_BINARY )\n",
            "    #cv2.imwrite(\"/Users/marius/Desktop/img_vh.jpg\", img_vh)\n",
            "    #cv2_imshow(img_vh)\n",
            "    \n",
            "    #print(\"result\")\n",
            "    #bitor but then 5->4 or 3\n",
            "    bitxor = cv2.bitwise_xor(img_bin, img_vh)\n",
            "    bitnot = cv2.bitwise_not(bitxor)\n",
            "    # Plotting the generated image\n",
            "    #cv2_imshow(bitnot)\n",
            "    \n",
            "    # Detect contours for following box detection\n",
            "    contours, hierarchy = cv2.findContours(img_vh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
            "    #print(len(contours))\n",
            "    #print(contours[0])\n",
            "    #print(len(contours[0]))\n",
            "    #print(cv2.boundingRect(contours[0]))\n",
            "\n",
            "    def sort_contours(cnts, method=\"left-to-right\"):\n",
            "        # initialize the reverse flag and sort index\n",
            "        reverse = False\n",
            "        i = 0\n",
            "        # handle if we need to sort in reverse\n",
            "        if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
            "            reverse = True\n",
            "        # handle if we are sorting against the y-coordinate rather than\n",
            "        # the x-coordinate of the bounding box\n",
            "        if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
            "            i = 1\n",
            "        # construct the list of bounding boxes and sort them from top to\n",
            "        # bottom\n",
            "        boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
            "        (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
            "                                            key=lambda b: b[1][i], reverse=reverse))\n",
            "        # return the list of sorted contours and bounding boxes\n",
            "        return (cnts, boundingBoxes)\n",
            "\n",
            "\n",
            "    # Sort all the contours by top to bottom.\n",
            "    contours, boundingBoxes = sort_contours(contours, method=\"top-to-bottom\")\n",
            "\n",
            "    # Creating a list of heights for all detected boxes\n",
            "    heights = [boundingBoxes[i][3] for i in range(len(boundingBoxes))]\n",
            "\n",
            "    # Get mean of heights\n",
            "    mean = np.mean(heights)\n",
            "\n",
            "    # Create list box to store all boxes in\n",
            "    box = []\n",
            "    # Get position (x,y), width and height for every contour and show the contour on image\n",
            "    #print(\"lencontours\", len(contours))\n",
            "    for c in contours:\n",
            "        x, y, w, h = cv2.boundingRect(c)\n",
            "        #print(\"x\", x, \"y\", y, \"w\", w, \"h\", h)\n",
            "        if (w < 0.9*img_width and h < 0.9*img_height):\n",
            "            image = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
            "            box.append([x, y, w, h])\n",
            "\n",
            "    #cv2_imshow(image)\n",
            "\n",
            "    # Creating two lists to define row and column in which cell is located\n",
            "    row = []\n",
            "    column = []\n",
            "    j = 0\n",
            "\n",
            "    #print(\"len box\", len(box))\n",
            "    # Sorting the boxes to their respective row and column\n",
            "    for i in range(len(box)):\n",
            "        if (i == 0):\n",
            "            column.append(box[i])\n",
            "            previous = box[i]\n",
            "\n",
            "        else:\n",
            "            if (box[i][1] <= previous[1] + mean / 2):\n",
            "                column.append(box[i])\n",
            "                previous = box[i]\n",
            "\n",
            "                if (i == len(box) - 1):\n",
            "                    row.append(column)\n",
            "\n",
            "            else:\n",
            "                row.append(column)\n",
            "                column = []\n",
            "                previous = box[i]\n",
            "                column.append(box[i])\n",
            "\n",
            "    #print(column)\n",
            "    #print(row)\n",
            "\n",
            "    # calculating maximum number of cells\n",
            "    countcol = 0\n",
            "    index = 0\n",
            "    for i in range(len(row)):\n",
            "        current = len(row[i])\n",
            "        #print(\"len\",len(row[i]))\n",
            "        if current > countcol:\n",
            "            countcol = current\n",
            "            index = i\n",
            "\n",
            "    #print(\"countcol\", countcol)\n",
            "\n",
            "    # Retrieving the center of each column\n",
            "    #center = [int(row[i][j][0] + row[i][j][2] / 2) for j in range(len(row[i])) if row[0]]\n",
            "    center = [int(row[index][j][0] + row[index][j][2] / 2) for j in range(len(row[index]))]\n",
            "    #print(\"center\",center)\n",
            "\n",
            "    center = np.array(center)\n",
            "    center.sort()\n",
            "    #print(\"center.sort()\", center)\n",
            "    # Regarding the distance to the columns center, the boxes are arranged in respective order\n",
            "\n",
            "    finalboxes = []\n",
            "    for i in range(len(row)):\n",
            "        lis = []\n",
            "        for k in range(countcol):\n",
            "            lis.append([])\n",
            "        for j in range(len(row[i])):\n",
            "            diff = abs(center - (row[i][j][0] + row[i][j][2] / 4))\n",
            "            minimum = min(diff)\n",
            "            indexing = list(diff).index(minimum)\n",
            "            lis[indexing].append(row[i][j])\n",
            "        finalboxes.append(lis)\n",
            "\n",
            "    \n",
            "    return finalboxes, img_bin"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfC4Tc0qyY-k"
      },
      "source": [
        "## 5. Initialize Table Detection Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40USlclsyW4K",
        "outputId": "fdfcd1a6-c0c5-4645-a2cd-110e8f716240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12/09 13:03:36 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from /content/model_final.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=torch.device(\"cpu\"))\n",
            "WARNING:fvcore.common.checkpoint:The checkpoint state_dict contains keys that are not used by the model:\n",
            "  pixel_mean\n",
            "  pixel_std\n"
          ]
        }
      ],
      "source": [
        "#create detectron config\n",
        "cfg = get_cfg()\n",
        "\n",
        "#set yaml\n",
        "cfg.merge_from_file('/content/All_X152.yaml')\n",
        "\n",
        "#set model weights\n",
        "cfg.MODEL.WEIGHTS = '/content/model_final.pth' # Set path model .pth\n",
        "\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Here"
      ],
      "metadata": {
        "id": "nDILF14eOncq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7Mer3eJfiUU"
      },
      "outputs": [],
      "source": [
        "document_img = cv2.imread(\"image2.jpeg\")\n",
        "table_detection.plot_prediction(document_img, predictor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pNfYu4kfj0V"
      },
      "outputs": [],
      "source": [
        "table_list, table_coords = table_detection.make_prediction(document_img, predictor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7SeIkt1fkaj"
      },
      "outputs": [],
      "source": [
        "list_table_boxes = []\n",
        "\n",
        "for table in table_list:\n",
        "    finalboxes, output_img = tsra.recognize_structure(table)\n",
        "    list_table_boxes.append(finalboxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zma6EJmcfmw1"
      },
      "outputs": [],
      "source": [
        "txml.output_to_xml(table_coords, list_table_boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrPbM0Vbfpni"
      },
      "outputs": [],
      "source": [
        "tocr.output_to_csv(list_table_boxes[0], output_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeDWYrvXyE2U",
        "outputId": "1966a337-e0db-45b6-f178-611dfddd1073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (11.0.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pdf2image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-2ZLVCXyIj0",
        "outputId": "6250368e-e85e-4a8e-c79c-285b766cffb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting poppler-utils\n",
            "  Downloading poppler_utils-0.1.0-py3-none-any.whl.metadata (883 bytes)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.10/dist-packages (from poppler-utils) (8.1.7)\n",
            "Downloading poppler_utils-0.1.0-py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: poppler-utils\n",
            "Successfully installed poppler-utils-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install poppler-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FOR PDF"
      ],
      "metadata": {
        "id": "A7TvEZM-OqYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import table_xml as txml  # Replace with the actual module name\n",
        "import table_ocr as tocr\n",
        "# Reload the module to reflect changes\n",
        "importlib.reload(txml)\n",
        "importlib.reload(tocr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jx6wwaNS8Xl",
        "outputId": "58e870f6-ddfd-48e4-85b9-a2da43f14cc1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'table_ocr' from '/content/table_ocr.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf __pycache__"
      ],
      "metadata": {
        "id": "yr2Pt2EjS4gQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2tSdwhsOuEZ",
        "outputId": "cdf7ddf1-d4c3-42a0-93d3-71728a95acf2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (11.0.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils\n",
        "import os\n",
        "os.environ['PATH'] += os.pathsep + '/usr/bin'\n",
        "# This line assumes pdfinfo is located in /usr/bin.\n",
        "# Adjust the path if it's different on your system.\n",
        "\n",
        "from pdf2image import convert_from_path\n",
        "import cv2\n",
        "import os\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3tq8TmEPR6L",
        "outputId": "9c4c07ec-2d49-4423-a90c-1de2826d4489"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 1s (139 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123679 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dIb84l2Oxnho"
      },
      "outputs": [],
      "source": [
        "from pdf2image import convert_from_path\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "h-vB3w0WvL8d"
      },
      "outputs": [],
      "source": [
        "def pdf_to_images(pdf_path, output_folder=\"pdf_pages\", dpi=300):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Convert PDF to list of images\n",
        "    images = convert_from_path(pdf_path, dpi=dpi)\n",
        "\n",
        "    image_paths = []\n",
        "    for idx, image in enumerate(images):\n",
        "        image_path = os.path.join(output_folder, f\"page_{idx + 1}.jpg\")\n",
        "        image.save(image_path, \"JPEG\")\n",
        "        image_paths.append(image_path)\n",
        "\n",
        "    return image_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z8Yh9YeyYTa",
        "outputId": "fd8b7e1e-da0b-4a53-88fd-49dfee219e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install poppler-utils\n",
        "import os\n",
        "os.environ['PATH'] += os.pathsep + '/usr/bin'\n",
        "# This line assumes pdfinfo is located in /usr/bin.\n",
        "# Adjust the path if it's different on your system.\n",
        "\n",
        "from pdf2image import convert_from_path\n",
        "import cv2\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/2407.01219v1.pdf\"\n"
      ],
      "metadata": {
        "id": "-QsF5laKPNPl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "j3jzx34Ux5ou"
      },
      "outputs": [],
      "source": [
        "def process_pdf_images(pdf_path, predictor, tsra, txml, tocr):\n",
        "    start_time_pdf2img = time.time()\n",
        "    image_paths = pdf_to_images(pdf_path)  # Convert PDF to images\n",
        "    end_time_pdf2img = time.time()\n",
        "    pdf2image_time = end_time_pdf2img - start_time_pdf2img\n",
        "\n",
        "    results_dir = \"results\"\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    # Initialize timers for each stage\n",
        "    time_make_prediction = 0\n",
        "    time_recognize_structure = 0\n",
        "    time_csv = 0\n",
        "    time_xml = 0\n",
        "\n",
        "    for idx, img_path in enumerate(image_paths):\n",
        "        try:\n",
        "            document_img = cv2.imread(img_path)\n",
        "            start_time_make_prediction = time.time()\n",
        "            table_list, table_coords = table_detection.make_prediction(document_img, predictor)\n",
        "            end_time_make_prediction = time.time()\n",
        "            time_make_prediction += end_time_make_prediction - start_time_make_prediction\n",
        "\n",
        "            list_table_boxes = []\n",
        "\n",
        "            for table_idx, table in enumerate(table_list):\n",
        "                try:\n",
        "                    start_time_recognize_structure = time.time()\n",
        "                    finalboxes, output_img = tsra.recognize_structure(table)\n",
        "                    end_time_recognize_structure = time.time()\n",
        "                    time_recognize_structure += end_time_recognize_structure - start_time_recognize_structure\n",
        "\n",
        "                    list_table_boxes.append(finalboxes)\n",
        "\n",
        "                    # Generate unique file names for each table\n",
        "                    xml_output_path = os.path.join(results_dir, f\"image_{idx + 1}_table_{table_idx + 1}.xml\")\n",
        "                    csv_output_path = os.path.join(results_dir, f\"image_{idx + 1}_table_{table_idx + 1}.xlsx\")\n",
        "\n",
        "                    # Save outputs for this table\n",
        "                    start_time_xml = time.time()\n",
        "                    txml.output_to_xml([table_coords[table_idx]], [finalboxes], xml_output_path)\n",
        "                    end_time_xml = time.time()\n",
        "                    time_xml += end_time_xml - start_time_xml\n",
        "\n",
        "                    start_time_csv = time.time()\n",
        "                    tocr.output_to_csv(finalboxes, output_img, csv_output_path)\n",
        "                    end_time_csv = time.time()\n",
        "                    time_csv += end_time_csv - start_time_csv\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing table {table_idx + 1} in image {idx + 1}: {e}\")\n",
        "                    continue  # Skip to the next table\n",
        "\n",
        "            print(f\"Processed image {idx + 1}/{len(image_paths)} with {len(table_list)} tables.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {idx + 1}: {e}\")\n",
        "            continue  # Skip to the next image\n",
        "\n",
        "    # Summary of processing times\n",
        "    print(\"All images processed.\")\n",
        "    print(f\"Time taken for PDF to images: {pdf2image_time:.2f} seconds\")\n",
        "    print(f\"Time taken for table detection (make_prediction): {time_make_prediction:.2f} seconds\")\n",
        "    print(f\"Time taken for table structure recognition: {time_recognize_structure:.2f} seconds\")\n",
        "    print(f\"Time taken for CSV generation: {time_csv:.2f} seconds\")\n",
        "    print(f\"Time taken for XML generation: {time_xml:.2f} seconds\")\n",
        "    total_time = pdf2image_time + time_make_prediction + time_recognize_structure + time_csv + time_xml\n",
        "    print(f\"Total processing time: {total_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_pdf=time.time()"
      ],
      "metadata": {
        "id": "FNqpapuYVrms"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_pdf_images(pdf_path,predictor,tsra,txml,tocr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etfFo3LISNsg",
        "outputId": "b7365271-bd15-405f-9a3d-1a6c327b5c07"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed image 1/22 with 1 tables.\n",
            "Processed image 2/22 with 0 tables.\n",
            "Processed image 3/22 with 0 tables.\n",
            "Processed image 4/22 with 1 tables.\n",
            "Processed image 5/22 with 2 tables.\n",
            "Error processing table 1 in image 6: list index out of range\n",
            "Processed image 6/22 with 2 tables.\n",
            "Error processing table 1 in image 7: list index out of range\n",
            "Processed image 7/22 with 2 tables.\n",
            "Processed image 8/22 with 2 tables.\n",
            "Processed image 9/22 with 1 tables.\n",
            "Processed image 10/22 with 0 tables.\n",
            "Processed image 11/22 with 1 tables.\n",
            "Processed image 12/22 with 0 tables.\n",
            "Error processing table 1 in image 13: list index out of range\n",
            "Processed image 13/22 with 1 tables.\n",
            "Processed image 14/22 with 0 tables.\n",
            "Processed image 15/22 with 0 tables.\n",
            "Processed image 16/22 with 0 tables.\n",
            "Processed image 17/22 with 0 tables.\n",
            "Processed image 18/22 with 0 tables.\n",
            "Processed image 19/22 with 0 tables.\n",
            "Processed image 20/22 with 1 tables.\n",
            "Processed image 21/22 with 2 tables.\n",
            "Error processing table 1 in image 22: list index out of range\n",
            "Processed image 22/22 with 1 tables.\n",
            "All images processed.\n",
            "Time taken for PDF to images: 5.18 seconds\n",
            "Time taken for table detection (make_prediction): 11.98 seconds\n",
            "Time taken for table structure recognition: 1.18 seconds\n",
            "Time taken for CSV generation: 217.85 seconds\n",
            "Time taken for XML generation: 0.02 seconds\n",
            "Total processing time: 236.20 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_pdf_images(pdf_path,predictor,tsra,txml,tocr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDJuZQAfjph4",
        "outputId": "e906ee59-7782-4673-bcee-8fd68ffe59b5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed image 1/22 with 1 tables.\n",
            "Processed image 2/22 with 0 tables.\n",
            "Processed image 3/22 with 0 tables.\n",
            "Processed image 4/22 with 1 tables.\n",
            "Processed image 5/22 with 2 tables.\n",
            "Error processing table 1 in image 6: list index out of range\n",
            "Processed image 6/22 with 2 tables.\n",
            "Error processing table 1 in image 7: list index out of range\n",
            "Processed image 7/22 with 2 tables.\n",
            "Processed image 8/22 with 2 tables.\n",
            "Processed image 9/22 with 1 tables.\n",
            "Processed image 10/22 with 0 tables.\n",
            "Processed image 11/22 with 1 tables.\n",
            "Processed image 12/22 with 0 tables.\n",
            "Error processing table 1 in image 13: list index out of range\n",
            "Processed image 13/22 with 1 tables.\n",
            "Processed image 14/22 with 0 tables.\n",
            "Processed image 15/22 with 0 tables.\n",
            "Processed image 16/22 with 0 tables.\n",
            "Processed image 17/22 with 0 tables.\n",
            "Processed image 18/22 with 0 tables.\n",
            "Processed image 19/22 with 0 tables.\n",
            "Processed image 20/22 with 1 tables.\n",
            "Processed image 21/22 with 2 tables.\n",
            "Error processing table 1 in image 22: list index out of range\n",
            "Processed image 22/22 with 1 tables.\n",
            "All images processed.\n",
            "Time taken for PDF to images: 5.10 seconds\n",
            "Time taken for table detection (make_prediction): 9.84 seconds\n",
            "Time taken for table structure recognition: 1.11 seconds\n",
            "Time taken for CSV generation: 216.11 seconds\n",
            "Time taken for XML generation: 0.02 seconds\n",
            "Total processing time: 232.16 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_time_pdf=time.time()"
      ],
      "metadata": {
        "id": "oEkrh00FVuDG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Time taken\",end_time_pdf-start_pdf)"
      ],
      "metadata": {
        "id": "7gNSRnCaVwID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c329524d-9ec9-4a39-a1c6-f850efd0b386"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken 247.7264633178711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path_2 = \"/content/VERIZON_2022_10K.pdf\"\n",
        "start_pdf=time.time()\n",
        "process_pdf_images(pdf_path_2,predictor,tsra,txml,tocr)\n",
        "end_time_pdf=time.time()\n",
        "print(\"Time taken\",end_time_pdf-start_pdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHDmnAuEewam",
        "outputId": "f4ea3b99-7dfb-4592-940b-ba41044dc3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed image 1/124 with 3 tables.\n",
            "Error processing table 1 in image 2: list index out of range\n",
            "Error processing table 4 in image 2: list index out of range\n",
            "Processed image 2/124 with 4 tables.\n",
            "Processed image 3/124 with 1 tables.\n",
            "Processed image 4/124 with 0 tables.\n",
            "Processed image 5/124 with 0 tables.\n",
            "Processed image 6/124 with 0 tables.\n",
            "Processed image 7/124 with 0 tables.\n",
            "Processed image 8/124 with 0 tables.\n",
            "Processed image 9/124 with 0 tables.\n",
            "Processed image 10/124 with 0 tables.\n",
            "Processed image 11/124 with 0 tables.\n",
            "Processed image 12/124 with 0 tables.\n",
            "Processed image 13/124 with 0 tables.\n",
            "Processed image 14/124 with 0 tables.\n",
            "Processed image 15/124 with 0 tables.\n",
            "Processed image 16/124 with 0 tables.\n",
            "Processed image 17/124 with 0 tables.\n",
            "Processed image 18/124 with 0 tables.\n",
            "Processed image 19/124 with 1 tables.\n",
            "Processed image 20/124 with 2 tables.\n",
            "Processed image 21/124 with 0 tables.\n",
            "Processed image 22/124 with 0 tables.\n",
            "Processed image 23/124 with 1 tables.\n",
            "Processed image 24/124 with 1 tables.\n",
            "Processed image 25/124 with 2 tables.\n",
            "Processed image 26/124 with 1 tables.\n",
            "Error processing table 2 in image 27: list index out of range\n",
            "Error processing table 4 in image 27: list index out of range\n",
            "Processed image 27/124 with 4 tables.\n",
            "Processed image 28/124 with 0 tables.\n",
            "Processed image 29/124 with 5 tables.\n",
            "Processed image 30/124 with 2 tables.\n",
            "Error processing table 2 in image 31: list index out of range\n",
            "Processed image 31/124 with 2 tables.\n",
            "Error processing table 4 in image 32: list index out of range\n",
            "Processed image 32/124 with 4 tables.\n",
            "Processed image 33/124 with 1 tables.\n",
            "Error processing table 4 in image 34: list index out of range\n",
            "Processed image 34/124 with 4 tables.\n",
            "Processed image 35/124 with 0 tables.\n",
            "Processed image 36/124 with 0 tables.\n",
            "Processed image 37/124 with 0 tables.\n",
            "Processed image 38/124 with 1 tables.\n",
            "Processed image 39/124 with 0 tables.\n",
            "Processed image 40/124 with 0 tables.\n",
            "Error processing table 2 in image 41: list index out of range\n",
            "Processed image 41/124 with 2 tables.\n",
            "Processed image 42/124 with 1 tables.\n",
            "Processed image 43/124 with 0 tables.\n",
            "Processed image 44/124 with 0 tables.\n",
            "Processed image 45/124 with 0 tables.\n",
            "Processed image 46/124 with 1 tables.\n",
            "Processed image 47/124 with 0 tables.\n",
            "Processed image 48/124 with 0 tables.\n",
            "Processed image 49/124 with 1 tables.\n",
            "Processed image 50/124 with 0 tables.\n",
            "Processed image 51/124 with 1 tables.\n",
            "Processed image 52/124 with 0 tables.\n",
            "Processed image 53/124 with 1 tables.\n",
            "Processed image 54/124 with 6 tables.\n",
            "Processed image 55/124 with 3 tables.\n",
            "Error processing table 3 in image 56: list index out of range\n",
            "Error processing table 5 in image 56: list index out of range\n",
            "Processed image 56/124 with 6 tables.\n",
            "Processed image 57/124 with 3 tables.\n",
            "Processed image 58/124 with 8 tables.\n",
            "Processed image 59/124 with 0 tables.\n",
            "Processed image 60/124 with 0 tables.\n",
            "Processed image 61/124 with 0 tables.\n",
            "Processed image 62/124 with 1 tables.\n",
            "Processed image 63/124 with 0 tables.\n",
            "Processed image 64/124 with 0 tables.\n",
            "Processed image 65/124 with 0 tables.\n",
            "Processed image 66/124 with 0 tables.\n",
            "Processed image 67/124 with 1 tables.\n",
            "Error processing table 3 in image 68: list index out of range\n",
            "Processed image 68/124 with 3 tables.\n",
            "Processed image 69/124 with 2 tables.\n",
            "Processed image 70/124 with 0 tables.\n",
            "Error processing table 1 in image 71: list index out of range\n",
            "Processed image 71/124 with 3 tables.\n",
            "Processed image 72/124 with 1 tables.\n",
            "Error processing table 2 in image 73: list index out of range\n",
            "Processed image 73/124 with 2 tables.\n",
            "Processed image 74/124 with 2 tables.\n",
            "Error processing table 4 in image 75: list index out of range\n",
            "Processed image 75/124 with 5 tables.\n",
            "Processed image 76/124 with 2 tables.\n",
            "Processed image 77/124 with 3 tables.\n",
            "Error processing table 4 in image 78: list index out of range\n",
            "Processed image 78/124 with 4 tables.\n",
            "Processed image 79/124 with 0 tables.\n",
            "Processed image 80/124 with 11 tables.\n",
            "Processed image 81/124 with 2 tables.\n",
            "Error processing table 5 in image 82: list index out of range\n",
            "Processed image 82/124 with 5 tables.\n",
            "Processed image 83/124 with 3 tables.\n",
            "Processed image 84/124 with 3 tables.\n",
            "Error processing table 1 in image 85: list index out of range\n",
            "Processed image 85/124 with 2 tables.\n",
            "Processed image 86/124 with 3 tables.\n",
            "Processed image 87/124 with 3 tables.\n",
            "Processed image 88/124 with 4 tables.\n",
            "Processed image 89/124 with 2 tables.\n",
            "Processed image 90/124 with 1 tables.\n",
            "Processed image 91/124 with 1 tables.\n",
            "Processed image 92/124 with 5 tables.\n",
            "Processed image 93/124 with 4 tables.\n",
            "Error processing table 5 in image 94: list index out of range\n",
            "Processed image 94/124 with 5 tables.\n",
            "Error processing table 4 in image 95: list index out of range\n",
            "Processed image 95/124 with 4 tables.\n",
            "Error processing table 3 in image 96: list index out of range\n",
            "Processed image 96/124 with 3 tables.\n",
            "Processed image 97/124 with 2 tables.\n",
            "Processed image 98/124 with 7 tables.\n",
            "Processed image 99/124 with 5 tables.\n",
            "Processed image 100/124 with 1 tables.\n",
            "Error processing table 5 in image 101: list index out of range\n",
            "Processed image 101/124 with 6 tables.\n",
            "Error processing table 4 in image 102: list index out of range\n",
            "Processed image 102/124 with 6 tables.\n",
            "Processed image 103/124 with 1 tables.\n",
            "Processed image 104/124 with 2 tables.\n",
            "Error processing table 5 in image 105: list index out of range\n",
            "Processed image 105/124 with 7 tables.\n",
            "Processed image 106/124 with 3 tables.\n",
            "Processed image 107/124 with 0 tables.\n",
            "Processed image 108/124 with 1 tables.\n",
            "Processed image 109/124 with 2 tables.\n",
            "Processed image 110/124 with 1 tables.\n",
            "Processed image 111/124 with 0 tables.\n",
            "Processed image 112/124 with 0 tables.\n",
            "Processed image 113/124 with 3 tables.\n",
            "Error processing table 1 in image 114: list index out of range\n",
            "Processed image 114/124 with 2 tables.\n",
            "Processed image 115/124 with 3 tables.\n",
            "Processed image 116/124 with 1 tables.\n",
            "Processed image 117/124 with 1 tables.\n",
            "Processed image 118/124 with 1 tables.\n",
            "Processed image 119/124 with 1 tables.\n",
            "Processed image 120/124 with 1 tables.\n",
            "Processed image 121/124 with 0 tables.\n",
            "Processed image 122/124 with 0 tables.\n",
            "Processed image 123/124 with 0 tables.\n",
            "Processed image 124/124 with 0 tables.\n",
            "Time taken 1951.2658166885376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_time_pdf=time.time()\n",
        "print(\"Time taken\",end_time_pdf-start_pdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t8aR2YOiHtP",
        "outputId": "4f6b7dea-2bed-409c-898b-963737f9b0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken 1960.200466632843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Path to the folder you want to compress and download\n",
        "folder_path = '/content/results'\n",
        "zip_filename = '/content/results.zip'\n",
        "\n",
        "# Compress the folder into a zip file\n",
        "shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', folder_path)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "eaVN-COYcDt9",
        "outputId": "ee856f95-ac23-4006-f73c-bc881d7bc847"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_025665c0-417c-40de-9e0b-ce31d4947514\", \"results.zip\", 10488)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree('/content/results', ignore_errors=True)\n",
        "shutil.rmtree('/content/pdf_pages', ignore_errors=True)\n"
      ],
      "metadata": {
        "id": "_ijK97kieovh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gm-hQbf0no6X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}